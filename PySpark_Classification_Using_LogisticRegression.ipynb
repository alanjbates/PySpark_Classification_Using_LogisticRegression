{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit a binary logistic regression model to the baby name dataset. \n",
    "#This model will predict the sex of a person based on the age, name, and state they were born in. \n",
    "#To train the model, I used data found in baby-names/names-classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file to df\n",
    "path = \"/FileStore/tables/streaming/names_*.csv\"\n",
    "autoschema = spark.read.load(path, format=\"csv\", sep=\",\", inferSchema=True, header=True)\n",
    "dataSchema = autoschema.schema\n",
    "autoschema.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we need to prepare each of the input features. \n",
    "#While age is a numeric feature, state and name are not. \n",
    "#These need to be converted into numeric vectors before we can train the model. \n",
    "\n",
    "#Use a StringIndexer along with the OneHotEncoderEstimator to convert the name, state, and sex columns into numeric vectors.\n",
    "#https://stackoverflow.com/questions/36942233/apply-stringindexer-to-several-columns-in-a-pyspark-dataframe\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(autoschema) for column in list(set(autoschema.columns)-set(['date'])) ]\n",
    "\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "df_r = pipeline.fit(autoschema).transform(autoschema)\n",
    "\n",
    "df_r.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/32982425/encode-and-assemble-multiple-features-in-pyspark\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "\n",
    "encoder = OneHotEncoderEstimator(inputCols=[\"name_index\", \"sex_index\", \"state_index\"], outputCols = [\"name_hot\", \"sex_hot\", \"state_hot\"])\n",
    "df_e = encoder.fit(df_r)\n",
    "df_ee = df_e.transform(df_r)\n",
    "df_ee.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the VectorAssembler to combine the name, state, and age vectors into a single features vector. \n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"name_hot\", \"sex_hot\", \"state_hot\"], outputCol=\"features\")\n",
    "\n",
    "df_vector = assembler.transform(df_ee)\n",
    "\n",
    "df_vector.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our final dataset should contain a column called features containing the prepared vector and a column called label containing the sex of the person.\n",
    "\n",
    "df_vector = df_vector.withColumnRenamed(\"sex_index\", \"label\")\n",
    "\n",
    "df_vector.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thedf = df_vector.select(\"label\", \"features\")\n",
    "thedf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Fit and Evaluate the Model\n",
    "\n",
    "#Fit the model as a logistic regression model with the following parameters. LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8). Provide the area under the ROC curve for the model.\n",
    "\n",
    "#https://spark.apache.org/docs/2.1.1/ml-classification-regression.html\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "(training, test) = thedf.randomSplit([0.8, 0.2])\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(training)\n",
    "\n",
    "# Print the coefficients and intercept for multinomial logistic regression\n",
    "print(\"Coefficients: \\n\" + str(lrModel.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(lrModel.interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = lrModel.transform(test)\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "evaluation = evaluator.evaluate(test_prediction)\n",
    "\n",
    "print(\"evaluation (area under ROC): %f\" % evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
